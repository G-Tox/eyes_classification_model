{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from shutil import copyfile\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_close_p = 'dataset/dataset_mrl/close'\n",
    "dir_open_p = 'dataset/dataset_mrl/open'\n",
    "dir_train_close='dataset/train_o/close'\n",
    "dir_test_close='dataset/test_o/close'\n",
    "dir_train_open='dataset/train_o/open'\n",
    "dir_test_open='dataset/test_o/open'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_close_left='dataset/dataset_eyes/closedLeftEyes'\n",
    "dir_close_right='dataset/dataset_eyes/closedRightEyes'\n",
    "dir_train_close='dataset/train/close'\n",
    "dir_test_close='dataset/test/close'\n",
    "dir_open_left='dataset/dataset_eyes/openLeftEyes'\n",
    "dir_open_right='dataset/dataset_eyes/openRightEyes'\n",
    "dir_train_open='dataset/train/open'\n",
    "dir_test_open='dataset/test/open'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset(dir_input,dir_train,dir_test):  \n",
    "    lista_new = os.listdir(dir_input)\n",
    "    num_train=int(len(lista_new)*0.9)\n",
    "    lista_random=random.sample(lista_new,len(lista_new))\n",
    "    lista_train=lista_random[:num_train]\n",
    "    lista_test=lista_random[num_train:]\n",
    "\n",
    "    for j in lista_train:\n",
    "        copyfile(dir_input+'/'+j,dir_train+'/'+j)\n",
    "\n",
    "    for k in lista_test:\n",
    "        copyfile(dir_input+'/'+k,dir_test+'/'+k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset(dir_close_p,dir_train_close,dir_test_close)\n",
    "dataset(dir_open_p,dir_train_open,dir_test_open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset(dir_close_left,dir_train_close,dir_test_close)\n",
    "dataset(dir_close_right,dir_train_close,dir_test_close)\n",
    "dataset(dir_open_left,dir_train_open,dir_test_open)\n",
    "dataset(dir_open_right,dir_train_open,dir_test_open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import requests\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Download data\n",
    "face = \"haarcascade.xml\"\n",
    "\n",
    "eye = \"eyecascade.xml\"\n",
    "\n",
    "image = \"dataset/data_own/IMG_5906.JPG\"\n",
    "\n",
    "\n",
    "#Classifiers\n",
    "face_cascade = cv2.CascadeClassifier(face)\n",
    "eye_cascade = cv2.CascadeClassifier(eye)\n",
    "\n",
    "#Image we will predict\n",
    "img = cv2.imread(image)\n",
    "plt.imshow(img)\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Detect face\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "\t#params = (image, position, width and height, color in RGB scale, and thickness)\n",
    "\timg = cv2.rectangle(img, (x,y), (x+w, y+h), (255,0,0), 2)\n",
    "\troi_gray = gray[y:y+h, x:x+w]\n",
    "\troi_color = img[y:y+h, x:x+w]\n",
    "\t#Detect eyes per face\n",
    "\teyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "\tfor (ex,ey,ew,eh) in eyes:\n",
    "\t\tcv2.rectangle(roi_color, (ex,ey), (ex+ew, ey+eh), (0,255,0), 2)\n",
    "\n",
    "\n",
    "#Show image\n",
    "cv2.namedWindow(\"image\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "while 1:\n",
    "\tcv2.imshow(\"image\", img)\n",
    "\tcv2.waitKey(1)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from mtcnn.mtcnn import MTCNN\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\mtcnn\\mtcnn.py:187: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\mtcnn\\mtcnn.py:193: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\mtcnn\\network.py:43: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\mtcnn\\layer_factory.py:88: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\mtcnn\\layer_factory.py:79: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\mtcnn\\layer_factory.py:171: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\mtcnn\\layer_factory.py:221: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\mtcnn\\layer_factory.py:196: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.\n",
      "\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[{'box': [1114, 582, 1246, 1563], 'confidence': 0.998357355594635, 'keypoints': {'left_eye': (1586, 1171), 'right_eye': (2164, 1124), 'nose': (1977, 1514), 'mouth_left': (1666, 1808), 'mouth_right': (2169, 1781)}}]\n",
      "[{'box': [1165, 481, 1249, 1567], 'confidence': 0.9994521737098694, 'keypoints': {'left_eye': (1614, 1066), 'right_eye': (2193, 1042), 'nose': (1965, 1408), 'mouth_left': (1669, 1701), 'mouth_right': (2168, 1695)}}]\n",
      "[]\n",
      "[]\n",
      "[{'box': [935, 558, 1294, 1597], 'confidence': 0.9970249533653259, 'keypoints': {'left_eye': (1341, 1128), 'right_eye': (1952, 1102), 'nose': (1682, 1478), 'mouth_left': (1395, 1776), 'mouth_right': (1940, 1772)}}]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[{'box': [1372, 1065, 294, 313], 'confidence': 0.8800289034843445, 'keypoints': {'left_eye': (1481, 1162), 'right_eye': (1598, 1164), 'nose': (1537, 1214), 'mouth_left': (1481, 1298), 'mouth_right': (1574, 1299)}}]\n",
      "[{'box': [1047, 556, 1280, 1603], 'confidence': 0.9999114274978638, 'keypoints': {'left_eye': (1483, 1192), 'right_eye': (2064, 1166), 'nose': (1830, 1526), 'mouth_left': (1528, 1791), 'mouth_right': (2053, 1785)}}]\n",
      "[{'box': [1075, 609, 1212, 1575], 'confidence': 0.9999352693557739, 'keypoints': {'left_eye': (1518, 1235), 'right_eye': (2082, 1196), 'nose': (1895, 1550), 'mouth_left': (1580, 1835), 'mouth_right': (2089, 1807)}}, {'box': [2837, 2147, 24, 29], 'confidence': 0.7837182283401489, 'keypoints': {'left_eye': (2845, 2160), 'right_eye': (2855, 2158), 'nose': (2852, 2165), 'mouth_left': (2847, 2171), 'mouth_right': (2856, 2170)}}]\n",
      "[{'box': [963, 452, 1264, 1626], 'confidence': 0.9997304081916809, 'keypoints': {'left_eye': (1427, 1124), 'right_eye': (2010, 1117), 'nose': (1790, 1464), 'mouth_left': (1472, 1742), 'mouth_right': (1993, 1744)}}]\n",
      "[{'box': [936, 479, 1196, 1591], 'confidence': 0.9991704225540161, 'keypoints': {'left_eye': (1368, 1131), 'right_eye': (1944, 1113), 'nose': (1765, 1473), 'mouth_left': (1436, 1747), 'mouth_right': (1951, 1732)}}]\n",
      "[{'box': [898, 441, 1150, 1543], 'confidence': 0.9968889355659485, 'keypoints': {'left_eye': (1216, 1083), 'right_eye': (1766, 1075), 'nose': (1484, 1414), 'mouth_left': (1248, 1663), 'mouth_right': (1738, 1667)}}]\n",
      "[{'box': [1093, 408, 1217, 1597], 'confidence': 0.9990384578704834, 'keypoints': {'left_eye': (1451, 1067), 'right_eye': (2029, 1030), 'nose': (1769, 1384), 'mouth_left': (1512, 1667), 'mouth_right': (2021, 1642)}}, {'box': [1598, 2324, 28, 35], 'confidence': 0.7661330103874207, 'keypoints': {'left_eye': (1611, 2335), 'right_eye': (1624, 2334), 'nose': (1622, 2343), 'mouth_left': (1612, 2351), 'mouth_right': (1623, 2350)}}]\n",
      "[{'box': [1157, 476, 1167, 1471], 'confidence': 0.9985381364822388, 'keypoints': {'left_eye': (1460, 1063), 'right_eye': (1990, 1053), 'nose': (1669, 1368), 'mouth_left': (1483, 1641), 'mouth_right': (1936, 1647)}}]\n",
      "[{'box': [1146, 530, 1137, 1401], 'confidence': 0.9999861717224121, 'keypoints': {'left_eye': (1419, 1037), 'right_eye': (1945, 1054), 'nose': (1615, 1362), 'mouth_left': (1440, 1609), 'mouth_right': (1873, 1634)}}]\n",
      "[{'box': [1242, 526, 1059, 1359], 'confidence': 0.9956793189048767, 'keypoints': {'left_eye': (1444, 1038), 'right_eye': (1926, 1061), 'nose': (1561, 1357), 'mouth_left': (1435, 1601), 'mouth_right': (1834, 1627)}}]\n",
      "[{'box': [1010, 506, 1087, 1339], 'confidence': 0.9998617172241211, 'keypoints': {'left_eye': (1272, 1001), 'right_eye': (1782, 1021), 'nose': (1443, 1305), 'mouth_left': (1288, 1565), 'mouth_right': (1701, 1589)}}]\n",
      "[{'box': [1192, 597, 1069, 1335], 'confidence': 0.9994733929634094, 'keypoints': {'left_eye': (1488, 1113), 'right_eye': (1977, 1112), 'nose': (1695, 1421), 'mouth_left': (1526, 1655), 'mouth_right': (1921, 1653)}}]\n",
      "[{'box': [1322, 597, 1041, 1301], 'confidence': 0.9992300271987915, 'keypoints': {'left_eye': (1630, 1116), 'right_eye': (2108, 1101), 'nose': (1861, 1384), 'mouth_left': (1680, 1640), 'mouth_right': (2066, 1637)}}]\n",
      "[{'box': [1358, 628, 1019, 1296], 'confidence': 0.9992235898971558, 'keypoints': {'left_eye': (1646, 1136), 'right_eye': (2117, 1131), 'nose': (1851, 1413), 'mouth_left': (1666, 1644), 'mouth_right': (2072, 1655)}}]\n",
      "[{'box': [1052, 618, 1065, 1337], 'confidence': 0.9986061453819275, 'keypoints': {'left_eye': (1326, 1152), 'right_eye': (1812, 1144), 'nose': (1518, 1438), 'mouth_left': (1352, 1686), 'mouth_right': (1763, 1689)}}]\n",
      "[{'box': [1025, 577, 1005, 1314], 'confidence': 0.99275803565979, 'keypoints': {'left_eye': (1234, 1087), 'right_eye': (1675, 1087), 'nose': (1356, 1371), 'mouth_left': (1246, 1614), 'mouth_right': (1616, 1616)}}, {'box': [526, 1961, 77, 88], 'confidence': 0.7169904708862305, 'keypoints': {'left_eye': (553, 1993), 'right_eye': (587, 1993), 'nose': (571, 2010), 'mouth_left': (556, 2031), 'mouth_right': (581, 2032)}}]\n"
     ]
    }
   ],
   "source": [
    "lista_foto_open = os.listdir('dataset/data_own/open_l')\n",
    "\n",
    "for name in lista_foto_open:\n",
    "    img = cv2.imread('dataset/data_own/open_l/'+name)\n",
    "    detector = MTCNN()\n",
    "    recog=detector.detect_faces(img)\n",
    "    print(recog)\n",
    "    \n",
    "    if recog:        \n",
    "        box=recog[0]['box']\n",
    "        ojo_iz = recog[0]['keypoints']['left_eye']\n",
    "        ojo_de = recog[0]['keypoints']['right_eye']\n",
    "        x=box[0]\n",
    "        y=box[1]\n",
    "        w=box[2]\n",
    "        h=box[3]\n",
    "\n",
    "        ojoiz_x=ojo_iz[0]\n",
    "        ojoiz_y=ojo_iz[1]\n",
    "\n",
    "        ojosd_x=ojo_de[0]\n",
    "        ojosd_y=ojo_de[1]\n",
    "\n",
    "        ojoiz_new_x = ojoiz_x - 230\n",
    "        ojoiz_new_y = ojoiz_y - 150\n",
    "        ojo_w = 450\n",
    "        ojo_h = 300\n",
    "\n",
    "        ojode_new_x = ojosd_x - 200\n",
    "        ojode_new_y = ojosd_y - 150\n",
    "\n",
    "        #img = cv2.rectangle(img, (ojoiz_new_x,ojoiz_new_y), (ojoiz_new_x+ojo_w, ojoiz_new_y+ojo_h), (100,100,100), 2)\n",
    "        #img = cv2.rectangle(img, (ojode_new_x,ojode_new_y), (ojode_new_x+ojo_w, ojode_new_y+ojo_h), (25,100,45), 2)\n",
    "        #img = cv2.rectangle(img, (x,y), (x+w, y+h), (255,0,0), 2)\n",
    "        #img = cv2.circle(img,(ojoiz_x,ojoiz_y),10,(255,0,255),3)\n",
    "        #img = cv2.circle(img,(ojosd_x,ojosd_y),20,(255,0,255),3)\n",
    "\n",
    "        name_eye = name[:-4]\n",
    "\n",
    "        crop_ojo_der = img[ojode_new_y:ojode_new_y+ojo_h, ojode_new_x:ojode_new_x+ojo_w]\n",
    "        cv2.imwrite(\"dataset/data_own/data_eye_open/right_\"+name_eye+\".jpg\", crop_ojo_der)\n",
    "\n",
    "        crop_ojo_iz = img[ojoiz_new_y:ojoiz_new_y+ojo_h, ojoiz_new_x:ojoiz_new_x+ojo_w]\n",
    "        cv2.imwrite(\"dataset/data_own/data_eye_open/left_\"+name_eye+\".jpg\", crop_ojo_iz)\n",
    "\n",
    "        #cv2.imwrite(\"dataset/data_own/IMG_5906_mo.JPG\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'box': [938, 540, 1323, 1643], 'confidence': 0.9974242448806763, 'keypoints': {'left_eye': (1309, 1137), 'right_eye': (1924, 1087), 'nose': (1629, 1486), 'mouth_left': (1377, 1789), 'mouth_right': (1934, 1769)}}]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[{'box': [1129, 403, 1217, 1606], 'confidence': 0.9986528158187866, 'keypoints': {'left_eye': (1506, 1062), 'right_eye': (2088, 1063), 'nose': (1810, 1395), 'mouth_left': (1552, 1674), 'mouth_right': (2056, 1675)}}]\n",
      "[{'box': [1217, 469, 1221, 1578], 'confidence': 0.9996863603591919, 'keypoints': {'left_eye': (1640, 1114), 'right_eye': (2211, 1136), 'nose': (1947, 1451), 'mouth_left': (1643, 1703), 'mouth_right': (2169, 1730)}}]\n",
      "[{'box': [1156, 474, 1219, 1566], 'confidence': 0.9998941421508789, 'keypoints': {'left_eye': (1598, 1115), 'right_eye': (2157, 1110), 'nose': (1942, 1414), 'mouth_left': (1621, 1683), 'mouth_right': (2141, 1676)}}]\n",
      "[{'box': [1035, 437, 1219, 1576], 'confidence': 0.9999237060546875, 'keypoints': {'left_eye': (1525, 1081), 'right_eye': (2073, 1080), 'nose': (1899, 1378), 'mouth_left': (1543, 1655), 'mouth_right': (2045, 1653)}}]\n",
      "[{'box': [1025, 433, 1213, 1558], 'confidence': 0.9999032020568848, 'keypoints': {'left_eye': (1501, 1067), 'right_eye': (2056, 1061), 'nose': (1875, 1353), 'mouth_left': (1523, 1631), 'mouth_right': (2044, 1627)}}]\n",
      "[{'box': [1054, 381, 1187, 1561], 'confidence': 0.9992768168449402, 'keypoints': {'left_eye': (1402, 1018), 'right_eye': (1977, 1039), 'nose': (1684, 1360), 'mouth_left': (1408, 1586), 'mouth_right': (1942, 1618)}}]\n",
      "[{'box': [1115, 488, 1208, 1538], 'confidence': 0.9989394545555115, 'keypoints': {'left_eye': (1507, 1117), 'right_eye': (2081, 1115), 'nose': (1817, 1441), 'mouth_left': (1526, 1678), 'mouth_right': (2056, 1687)}}]\n",
      "[{'box': [1055, 418, 1264, 1583], 'confidence': 0.9993670582771301, 'keypoints': {'left_eye': (1468, 1070), 'right_eye': (2059, 1065), 'nose': (1788, 1401), 'mouth_left': (1493, 1654), 'mouth_right': (2032, 1655)}}]\n",
      "[{'box': [960, 393, 1275, 1612], 'confidence': 0.9997714161872864, 'keypoints': {'left_eye': (1404, 1083), 'right_eye': (1991, 1086), 'nose': (1727, 1417), 'mouth_left': (1426, 1668), 'mouth_right': (1962, 1677)}}]\n",
      "[{'box': [1325, 259, 1188, 1559], 'confidence': 0.9995909333229065, 'keypoints': {'left_eye': (1675, 896), 'right_eye': (2237, 901), 'nose': (1954, 1233), 'mouth_left': (1681, 1455), 'mouth_right': (2204, 1466)}}]\n",
      "[{'box': [1257, 496, 1170, 1509], 'confidence': 0.9976420998573303, 'keypoints': {'left_eye': (1599, 1115), 'right_eye': (2165, 1135), 'nose': (1865, 1455), 'mouth_left': (1607, 1678), 'mouth_right': (2119, 1706)}}]\n",
      "[{'box': [1029, 606, 1036, 1256], 'confidence': 0.9999754428863525, 'keypoints': {'left_eye': (1283, 1079), 'right_eye': (1758, 1099), 'nose': (1456, 1358), 'mouth_left': (1297, 1598), 'mouth_right': (1700, 1622)}}]\n",
      "[{'box': [1070, 613, 977, 1272], 'confidence': 0.9871978163719177, 'keypoints': {'left_eye': (1254, 1101), 'right_eye': (1698, 1118), 'nose': (1369, 1375), 'mouth_left': (1257, 1613), 'mouth_right': (1633, 1629)}}]\n",
      "[{'box': [957, 636, 1007, 1297], 'confidence': 0.9919344186782837, 'keypoints': {'left_eye': (1146, 1131), 'right_eye': (1590, 1146), 'nose': (1250, 1416), 'mouth_left': (1130, 1648), 'mouth_right': (1519, 1666)}}]\n",
      "[{'box': [1236, 643, 1053, 1309], 'confidence': 0.9996650218963623, 'keypoints': {'left_eye': (1520, 1163), 'right_eye': (1989, 1146), 'nose': (1716, 1432), 'mouth_left': (1557, 1674), 'mouth_right': (1954, 1670)}}]\n",
      "[{'box': [1165, 662, 1050, 1313], 'confidence': 0.9999802112579346, 'keypoints': {'left_eye': (1443, 1187), 'right_eye': (1931, 1190), 'nose': (1649, 1474), 'mouth_left': (1471, 1710), 'mouth_right': (1882, 1718)}}]\n",
      "[{'box': [1196, 653, 1026, 1312], 'confidence': 0.9997379183769226, 'keypoints': {'left_eye': (1475, 1190), 'right_eye': (1948, 1188), 'nose': (1682, 1462), 'mouth_left': (1501, 1694), 'mouth_right': (1914, 1698)}}]\n",
      "[{'box': [1216, 629, 1050, 1322], 'confidence': 0.999298095703125, 'keypoints': {'left_eye': (1494, 1143), 'right_eye': (1981, 1128), 'nose': (1714, 1419), 'mouth_left': (1545, 1663), 'mouth_right': (1947, 1651)}}]\n",
      "[{'box': [1195, 643, 1048, 1313], 'confidence': 0.9998689889907837, 'keypoints': {'left_eye': (1472, 1158), 'right_eye': (1962, 1156), 'nose': (1681, 1450), 'mouth_left': (1507, 1681), 'mouth_right': (1928, 1684)}}]\n",
      "[{'box': [1250, 670, 1042, 1282], 'confidence': 0.9997836947441101, 'keypoints': {'left_eye': (1522, 1178), 'right_eye': (1985, 1165), 'nose': (1707, 1453), 'mouth_left': (1545, 1671), 'mouth_right': (1958, 1665)}}]\n",
      "[{'box': [1308, 683, 1018, 1275], 'confidence': 0.9999054670333862, 'keypoints': {'left_eye': (1542, 1203), 'right_eye': (2011, 1199), 'nose': (1712, 1507), 'mouth_left': (1569, 1704), 'mouth_right': (1976, 1710)}}]\n"
     ]
    }
   ],
   "source": [
    "lista_foto_close = os.listdir('dataset/data_own/close_l')\n",
    "\n",
    "for name in lista_foto_close:\n",
    "    img = cv2.imread('dataset/data_own/close_l/'+name)\n",
    "    detector = MTCNN()\n",
    "    recog=detector.detect_faces(img)\n",
    "    print(recog)\n",
    "    \n",
    "    if recog:\n",
    "        box=recog[0]['box']\n",
    "        ojo_iz = recog[0]['keypoints']['left_eye']\n",
    "        ojo_de = recog[0]['keypoints']['right_eye']\n",
    "        x=box[0]\n",
    "        y=box[1]\n",
    "        w=box[2]\n",
    "        h=box[3]\n",
    "\n",
    "        ojoiz_x=ojo_iz[0]\n",
    "        ojoiz_y=ojo_iz[1]\n",
    "\n",
    "        ojosd_x=ojo_de[0]\n",
    "        ojosd_y=ojo_de[1]\n",
    "\n",
    "        ojoiz_new_x = ojoiz_x - 230\n",
    "        ojoiz_new_y = ojoiz_y - 150\n",
    "        ojo_w = 450\n",
    "        ojo_h = 300\n",
    "\n",
    "        ojode_new_x = ojosd_x - 200\n",
    "        ojode_new_y = ojosd_y - 150\n",
    "\n",
    "        #img = cv2.rectangle(img, (ojoiz_new_x,ojoiz_new_y), (ojoiz_new_x+ojo_w, ojoiz_new_y+ojo_h), (100,100,100), 2)\n",
    "        #img = cv2.rectangle(img, (ojode_new_x,ojode_new_y), (ojode_new_x+ojo_w, ojode_new_y+ojo_h), (25,100,45), 2)\n",
    "        #img = cv2.rectangle(img, (x,y), (x+w, y+h), (255,0,0), 2)\n",
    "        #img = cv2.circle(img,(ojoiz_x,ojoiz_y),10,(255,0,255),3)\n",
    "        #img = cv2.circle(img,(ojosd_x,ojosd_y),20,(255,0,255),3)\n",
    "\n",
    "        name_eye = name[:-4]\n",
    "\n",
    "        crop_ojo_der = img[ojode_new_y:ojode_new_y+ojo_h, ojode_new_x:ojode_new_x+ojo_w]\n",
    "        cv2.imwrite(\"dataset/data_own/data_eye_close/right\"+name_eye+\".jpg\", crop_ojo_der)\n",
    "\n",
    "        crop_ojo_iz = img[ojoiz_new_y:ojoiz_new_y+ojo_h, ojoiz_new_x:ojoiz_new_x+ojo_w]\n",
    "        cv2.imwrite(\"dataset/data_own/data_eye_close/left\"+name_eye+\".jpg\", crop_ojo_iz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_close_p = 'dataset/data_own/data_eye_close'\n",
    "dir_train_close = 'dataset/train_own/close'\n",
    "dir_test_close = 'dataset/valid_own/close'\n",
    "dir_open_p = 'dataset/data_own/data_eye_open'\n",
    "dir_train_open = 'dataset/train_own/open'\n",
    "dir_test_open = 'dataset/valid_own/open'\n",
    "\n",
    "dataset(dir_close_p,dir_train_close,dir_test_close)\n",
    "dataset(dir_open_p,dir_train_open,dir_test_open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\mtcnn\\mtcnn.py:187: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\mtcnn\\mtcnn.py:193: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\mtcnn\\network.py:43: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\mtcnn\\layer_factory.py:88: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\mtcnn\\layer_factory.py:79: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\mtcnn\\layer_factory.py:171: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\mtcnn\\layer_factory.py:221: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP\\lib\\site-packages\\mtcnn\\layer_factory.py:196: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.\n",
      "\n",
      "[{'box': [277, 164, 161, 208], 'confidence': 0.998752236366272, 'keypoints': {'left_eye': (325, 239), 'right_eye': (399, 237), 'nose': (363, 287), 'mouth_left': (333, 328), 'mouth_right': (395, 326)}}]\n",
      "[{'box': [274, 163, 158, 206], 'confidence': 0.9990744590759277, 'keypoints': {'left_eye': (320, 240), 'right_eye': (394, 235), 'nose': (357, 284), 'mouth_left': (328, 327), 'mouth_right': (389, 325)}}]\n",
      "[{'box': [265, 177, 155, 197], 'confidence': 0.995999813079834, 'keypoints': {'left_eye': (313, 246), 'right_eye': (382, 247), 'nose': (348, 292), 'mouth_left': (312, 328), 'mouth_right': (376, 330)}}]\n"
     ]
    }
   ],
   "source": [
    "from mtcnn.mtcnn import MTCNN\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "model = load_model('models/model.h5')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while (True):\n",
    "    ret, img = cap.read()\n",
    "    #frame_id += 1\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    detector = MTCNN()\n",
    "    recog=detector.detect_faces(img)\n",
    "    print(recog)\n",
    "\n",
    "    if recog:\n",
    "        box=recog[0]['box']\n",
    "        x=box[0]\n",
    "        y=box[1]\n",
    "        w=box[2]\n",
    "        h=box[3]\n",
    "\n",
    "        crop_face = img[y-50:(y)+(h+50),(x-50):(x)+(w+50)]\n",
    "        crop_face = cv2.resize(crop_face, (830,900))\n",
    "        #cv2.imwrite(\"dataset/img_test/resize.jpg\", crop_face)\n",
    "        img = cv2.rectangle(img, (x,y), (x+w, y+h), (255,0,0), 10)\n",
    "\n",
    "        detector8 = MTCNN()\n",
    "        recog_eyes = detector8.detect_faces(crop_face)\n",
    "\n",
    "        if recog_eyes:\n",
    "\n",
    "            ojo_iz = recog_eyes[0]['keypoints']['left_eye']\n",
    "            ojo_de = recog_eyes[0]['keypoints']['right_eye']\n",
    "\n",
    "            ojoiz_x=ojo_iz[0]\n",
    "            ojoiz_y=ojo_iz[1]\n",
    "\n",
    "            ojosd_x=ojo_de[0]\n",
    "            ojosd_y=ojo_de[1]\n",
    "\n",
    "            ojoiz_new_x = ojoiz_x - 120\n",
    "            ojoiz_new_y = ojoiz_y - 90\n",
    "            ojo_w = 200\n",
    "            ojo_h = 150\n",
    "\n",
    "            ojode_new_x = ojosd_x - 110\n",
    "            ojode_new_y = ojosd_y - 90\n",
    "\n",
    "            #ojoiz_new_x = ojoiz_x - 230\n",
    "            #ojoiz_new_y = ojoiz_y - 150\n",
    "            #ojo_w = 450\n",
    "            #ojo_h = 300\n",
    "\n",
    "            #ojode_new_x = ojosd_x - 200\n",
    "            #ojode_new_y = ojosd_y - 150\n",
    "\n",
    "\n",
    "            #img = cv2.rectangle(img, (ojoiz_new_x,ojoiz_new_y), (ojoiz_new_x+ojo_w, ojoiz_new_y+ojo_h), (100,100,100), 2)\n",
    "            #img = cv2.rectangle(img, (ojode_new_x,ojode_new_y), (ojode_new_x+ojo_w, ojode_new_y+ojo_h), (25,100,45), 2)\n",
    "            #img = cv2.circle(img,(ojoiz_x,ojoiz_y),10,(255,0,255),3)\n",
    "            #img = cv2.circle(img,(ojosd_x,ojosd_y),20,(255,0,255),3)\n",
    "\n",
    "            #cv2.imwrite(\"dataset/img_test/cerrar-ojos-12.jpg\", img)\n",
    "\n",
    "            crop_ojo_der = crop_face[ojode_new_y:ojode_new_y+ojo_h, ojode_new_x:ojode_new_x+ojo_w]\n",
    "            output = cv2.resize(crop_ojo_der, (200,200))\n",
    "            #cv2.imwrite(\"dataset/img_test/resize_ojo.jpg\", crop_ojo_der)\n",
    "            x=image.img_to_array(output)\n",
    "            x=np.expand_dims(x, axis=0)\n",
    "            images = np.vstack([x])\n",
    "            classes = None\n",
    "            classes = model.predict(images, batch_size=10)\n",
    "\n",
    "            if classes >=0.5:\n",
    "                texto = 'Ojo Izquierdo abierto'\n",
    "                cv2.putText(img, texto, (10,10), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 0, 0), 3)\n",
    "                cv2.putText(img, texto, (10,10), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)\n",
    "\n",
    "            elif classes < 0.5:\n",
    "                texto = 'Ojo Izquierdo cerrado'\n",
    "                cv2.putText(img, texto, (b_d[0], b_d[1] - 30), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 0, 0), 3)\n",
    "                cv2.putText(img, texto, (b_d[0], b_d[1] - 30), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)\n",
    "\n",
    "            crop_ojo_iz = crop_face[ojoiz_new_y:ojoiz_new_y+ojo_h, ojoiz_new_x:ojoiz_new_x+ojo_w]\n",
    "            output_1 = cv2.resize(crop_ojo_iz, (200,200)) \n",
    "            #cv2.imwrite(\"dataset/img_test/resize_1.jpg\", crop_ojo_iz)\n",
    "            x_1=image.img_to_array(output_1)\n",
    "            x_1=np.expand_dims(x_1, axis=0)\n",
    "            images_1 = np.vstack([x_1])\n",
    "            classes_1 = None\n",
    "            classes_1 = model.predict(images_1, batch_size=10)\n",
    "\n",
    "            if classes_1 >=0.5:\n",
    "                texto = 'Ojo derecho abierto'\n",
    "                cv2.putText(img, texto, (10,10), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 0, 0), 3)\n",
    "                cv2.putText(img, texto, (10,10), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)\n",
    "\n",
    "            elif classes_1 < 0.5:\n",
    "                texto = 'Ojo derecho cerrado'\n",
    "                cv2.putText(img, texto, (30,30), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 0, 0), 3)\n",
    "                cv2.putText(img, texto, (30,30), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)\n",
    "\n",
    "        else:\n",
    "            print(' no se reconocio los ojos')\n",
    "        \n",
    "    cv2.imshow(\"Image\", img)\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\mtcnn.py:187: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\mtcnn.py:193: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\network.py:43: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\layer_factory.py:88: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\layer_factory.py:79: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\layer_factory.py:171: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\layer_factory.py:221: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\layer_factory.py:196: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.\n",
      "\n",
      "[]\n",
      "[{'box': [271, 210, 163, 211], 'confidence': 0.999963641166687, 'keypoints': {'left_eye': (322, 286), 'right_eye': (400, 286), 'nose': (366, 328), 'mouth_left': (331, 378), 'mouth_right': (393, 376)}}]\n",
      "[{'box': [279, 89, 176, 224], 'confidence': 0.9999502897262573, 'keypoints': {'left_eye': (334, 175), 'right_eye': (418, 175), 'nose': (380, 225), 'mouth_left': (343, 271), 'mouth_right': (410, 271)}}]\n",
      "[{'box': [279, 147, 167, 223], 'confidence': 0.9993670582771301, 'keypoints': {'left_eye': (333, 231), 'right_eye': (412, 231), 'nose': (372, 271), 'mouth_left': (336, 321), 'mouth_right': (403, 321)}}]\n",
      "[{'box': [260, 121, 170, 223], 'confidence': 0.9987215399742126, 'keypoints': {'left_eye': (318, 207), 'right_eye': (397, 207), 'nose': (361, 249), 'mouth_left': (323, 297), 'mouth_right': (390, 297)}}]\n",
      "[{'box': [260, 120, 179, 241], 'confidence': 0.9933046698570251, 'keypoints': {'left_eye': (319, 209), 'right_eye': (402, 209), 'nose': (360, 263), 'mouth_left': (321, 308), 'mouth_right': (393, 308)}}]\n",
      "[{'box': [254, 118, 179, 235], 'confidence': 0.9972037076950073, 'keypoints': {'left_eye': (313, 208), 'right_eye': (395, 209), 'nose': (357, 263), 'mouth_left': (319, 308), 'mouth_right': (387, 309)}}]\n",
      "[{'box': [259, 121, 177, 239], 'confidence': 0.9960565567016602, 'keypoints': {'left_eye': (321, 210), 'right_eye': (402, 211), 'nose': (366, 260), 'mouth_left': (325, 308), 'mouth_right': (392, 309)}}]\n",
      "[{'box': [257, 120, 180, 237], 'confidence': 0.9989043474197388, 'keypoints': {'left_eye': (315, 208), 'right_eye': (400, 207), 'nose': (361, 259), 'mouth_left': (322, 305), 'mouth_right': (392, 304)}}]\n",
      "[{'box': [250, 135, 190, 257], 'confidence': 0.9935408234596252, 'keypoints': {'left_eye': (322, 235), 'right_eye': (408, 231), 'nose': (384, 300), 'mouth_left': (331, 345), 'mouth_right': (404, 342)}}]\n"
     ]
    }
   ],
   "source": [
    "from mtcnn.mtcnn import MTCNN\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "model = load_model('models/model_1.h5')\n",
    "\n",
    "#Creamos un objeto que iniciará la captura de video en la primera entrada disponible (la 0)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "#Iniciamos un bucle continua\n",
    "while(True):\n",
    "    #Dos objetos irán grabando las imágenes del objeto cap\n",
    "    ret, img = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    detector = MTCNN()\n",
    "    recog=detector.detect_faces(img)\n",
    "    print(recog)\n",
    "\n",
    "    if recog:\n",
    "        box=recog[0]['box']\n",
    "        x=box[0]\n",
    "        y=box[1]\n",
    "        w=box[2]\n",
    "        h=box[3]\n",
    "\n",
    "        crop_face = img[y-50:(y)+(h+50),(x-50):(x)+(w+50)]\n",
    "        crop_face = cv2.resize(crop_face, (830,900))\n",
    "        #cv2.imwrite(\"dataset/img_test/resize.jpg\", crop_face)\n",
    "        img = cv2.rectangle(img, (x,y), (x+w, y+h), (255,0,0), 2)\n",
    "        \n",
    "        detector8 = MTCNN()\n",
    "        recog_eyes = detector8.detect_faces(crop_face)\n",
    "\n",
    "        if recog_eyes:\n",
    "\n",
    "            ojo_iz = recog_eyes[0]['keypoints']['left_eye']\n",
    "            ojo_de = recog_eyes[0]['keypoints']['right_eye']\n",
    "\n",
    "            ojoiz_x=ojo_iz[0]\n",
    "            ojoiz_y=ojo_iz[1]\n",
    "\n",
    "            ojosd_x=ojo_de[0]\n",
    "            ojosd_y=ojo_de[1]\n",
    "\n",
    "            ojoiz_new_x = ojoiz_x - 120\n",
    "            ojoiz_new_y = ojoiz_y - 90\n",
    "            ojo_w = 200\n",
    "            ojo_h = 150\n",
    "\n",
    "            ojode_new_x = ojosd_x - 110\n",
    "            ojode_new_y = ojosd_y - 90\n",
    "            \n",
    "    cv2.imshow('Hola Mundo',img)\n",
    "\n",
    "    #el procedimiento waitKey comprueba si se ha pulsado la tecla 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Si se ha roto el bucle, procedemos a destruir la ventana y finalizar el programa\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "crop_ojo_der = img[ojode_new_y:ojode_new_y+ojo_h, ojode_new_x:ojode_new_x+ojo_w]\n",
    "cv2.imwrite(\"dataset/img_test/resize.jpg\", crop_ojo_der)\n",
    "output = cv2.resize(crop_ojo_der, (200,200))\n",
    "x=image.img_to_array(output)\n",
    "x=np.expand_dims(x, axis=0)\n",
    "images = np.vstack([x])\n",
    "classes = None\n",
    "classes = model.predict(images, batch_size=10)\n",
    "print(classes[0])\n",
    "    \n",
    "crop_ojo_iz = img[ojoiz_new_y:ojoiz_new_y+ojo_h, ojoiz_new_x:ojoiz_new_x+ojo_w]\n",
    "output_1 = cv2.resize(crop_ojo_iz, (200,200)) \n",
    "cv2.imwrite(\"dataset/img_test/resize_1.jpg\", output_1)\n",
    "x_1=image.img_to_array(output_1)\n",
    "x_1=np.expand_dims(x_1, axis=0)\n",
    "images_1 = np.vstack([x_1])\n",
    "classes_1 = None\n",
    "classes_1 = model.predict(images_1, batch_size=10)\n",
    "print(classes_1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 14898910522840973515\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3203543859\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 13927022658980315416\n",
      "physical_device_desc: \"device: 0, name: GeForce MX130, pci bus id: 0000:01:00.0, compute capability: 5.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\mtcnn.py:187: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\mtcnn.py:193: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\network.py:43: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\layer_factory.py:88: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\layer_factory.py:79: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\layer_factory.py:171: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\layer_factory.py:221: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\layer_factory.py:196: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.\n",
      "\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "2 root error(s) found.\n  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node pnet/conv1/Conv2D (defined at C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\layer_factory.py:121) ]]\n  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node pnet/conv1/Conv2D (defined at C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\layer_factory.py:121) ]]\n\t [[pnet/prob1/_105]]\n0 successful operations.\n0 derived errors ignored.\n\nErrors may have originated from an input operation.\nInput Source operations connected to node pnet/conv1/Conv2D:\n pnet/conv1/weights/read (defined at C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\layer_factory.py:79)\t\n pnet/input (defined at C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\layer_factory.py:88)\n\nInput Source operations connected to node pnet/conv1/Conv2D:\n pnet/conv1/weights/read (defined at C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\layer_factory.py:79)\t\n pnet/input (defined at C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\layer_factory.py:88)\n\nOriginal stack trace for 'pnet/conv1/Conv2D':\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 149, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\asyncio\\base_events.py\", line 442, in run_forever\n    self._run_once()\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\asyncio\\base_events.py\", line 1462, in _run_once\n    handle._run()\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2867, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2895, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3072, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-e99b56b0fa62>\", line 10, in <module>\n    detector = MTCNN()\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\mtcnn.py\", line 196, in __init__\n    self.__pnet = PNet(self.__session, False)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\network.py\", line 44, in __init__\n    self._config()\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\mtcnn.py\", line 55, in _config\n    padding='VALID', relu=False)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\layer_factory.py\", line 126, in new_conv\n    output = convolve(input_layer, kernel)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\layer_factory.py\", line 121, in <lambda>\n    padding=padding)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 1953, in conv2d\n    name=name)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1161, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1355\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1356\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1357\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1341\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1429\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: 2 root error(s) found.\n  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node pnet/conv1/Conv2D}}]]\n  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node pnet/conv1/Conv2D}}]]\n\t [[pnet/prob1/_105]]\n0 successful operations.\n0 derived errors ignored.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e99b56b0fa62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dataset/img_test/IMG_5920.JPG\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mdetector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMTCNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mrecog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect_faces\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\mtcnn.py\u001b[0m in \u001b[0;36mdetect_faces\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[1;31m# We pipe here each of the stages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mstage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 418\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[1;33m[\u001b[0m\u001b[0mtotal_boxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\mtcnn.py\u001b[0m in \u001b[0;36m__stage1\u001b[1;34m(self, image, scales, stage_status)\u001b[0m\n\u001b[0;32m    457\u001b[0m             \u001b[0mimg_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 459\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__pnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m             \u001b[0mout0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\network.py\u001b[0m in \u001b[0;36mfeed\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_feed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\mtcnn.py\u001b[0m in \u001b[0;36m_feed\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_feed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pnet/conv4-2/BiasAdd:0'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'pnet/prob1:0'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'pnet/input:0'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 950\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    951\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1171\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1173\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1174\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1350\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1368\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: 2 root error(s) found.\n  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node pnet/conv1/Conv2D (defined at C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\layer_factory.py:121) ]]\n  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node pnet/conv1/Conv2D (defined at C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\layer_factory.py:121) ]]\n\t [[pnet/prob1/_105]]\n0 successful operations.\n0 derived errors ignored.\n\nErrors may have originated from an input operation.\nInput Source operations connected to node pnet/conv1/Conv2D:\n pnet/conv1/weights/read (defined at C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\layer_factory.py:79)\t\n pnet/input (defined at C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\layer_factory.py:88)\n\nInput Source operations connected to node pnet/conv1/Conv2D:\n pnet/conv1/weights/read (defined at C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\layer_factory.py:79)\t\n pnet/input (defined at C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\layer_factory.py:88)\n\nOriginal stack trace for 'pnet/conv1/Conv2D':\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 149, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\asyncio\\base_events.py\", line 442, in run_forever\n    self._run_once()\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\asyncio\\base_events.py\", line 1462, in _run_once\n    handle._run()\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2867, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2895, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3072, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-e99b56b0fa62>\", line 10, in <module>\n    detector = MTCNN()\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\mtcnn.py\", line 196, in __init__\n    self.__pnet = PNet(self.__session, False)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\network.py\", line 44, in __init__\n    self._config()\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\mtcnn.py\", line 55, in _config\n    padding='VALID', relu=False)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\layer_factory.py\", line 126, in new_conv\n    output = convolve(input_layer, kernel)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\mtcnn\\layer_factory.py\", line 121, in <lambda>\n    padding=padding)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 1953, in conv2d\n    name=name)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1161, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Inspira\\.conda\\envs\\NLP-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "from mtcnn.mtcnn import MTCNN\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "model = load_model('models/model.h5')\n",
    "\n",
    "img = cv2.imread(\"dataset/img_test/IMG_5920.JPG\")\n",
    "detector = MTCNN()\n",
    "recog=detector.detect_faces(img)\n",
    "print(recog)\n",
    "\n",
    "if recog:\n",
    "    box=recog[0]['box']\n",
    "    x=box[0]\n",
    "    y=box[1]\n",
    "    w=box[2]\n",
    "    h=box[3]\n",
    "\n",
    "    crop_face = img[y-50:(y)+(h+50),(x-50):(x)+(w+50)]\n",
    "    crop_face = cv2.resize(crop_face, (830,900))\n",
    "        #cv2.imwrite(\"dataset/img_test/resize.jpg\", crop_face)\n",
    "    img = cv2.rectangle(img, (x,y), (x+w, y+h), (255,0,0), 10)\n",
    "\n",
    "    detector8 = MTCNN()\n",
    "    recog_eyes = detector8.detect_faces(crop_face)\n",
    "\n",
    "    if recog_eyes:\n",
    "\n",
    "        ojo_iz = recog_eyes[0]['keypoints']['left_eye']\n",
    "        ojo_de = recog_eyes[0]['keypoints']['right_eye']\n",
    "\n",
    "        ojoiz_x=ojo_iz[0]\n",
    "        ojoiz_y=ojo_iz[1]\n",
    "\n",
    "        ojosd_x=ojo_de[0]\n",
    "        ojosd_y=ojo_de[1]\n",
    "\n",
    "        ojoiz_new_x = ojoiz_x - 120\n",
    "        ojoiz_new_y = ojoiz_y - 90\n",
    "        ojo_w = 200\n",
    "        ojo_h = 150\n",
    "\n",
    "        ojode_new_x = ojosd_x - 110\n",
    "        ojode_new_y = ojosd_y - 90\n",
    "\n",
    "            #ojoiz_new_x = ojoiz_x - 230\n",
    "            #ojoiz_new_y = ojoiz_y - 150\n",
    "            #ojo_w = 450\n",
    "            #ojo_h = 300\n",
    "\n",
    "            #ojode_new_x = ojosd_x - 200\n",
    "            #ojode_new_y = ojosd_y - 150\n",
    "\n",
    "\n",
    "            #img = cv2.rectangle(img, (ojoiz_new_x,ojoiz_new_y), (ojoiz_new_x+ojo_w, ojoiz_new_y+ojo_h), (100,100,100), 2)\n",
    "            #img = cv2.rectangle(img, (ojode_new_x,ojode_new_y), (ojode_new_x+ojo_w, ojode_new_y+ojo_h), (25,100,45), 2)\n",
    "            #img = cv2.circle(img,(ojoiz_x,ojoiz_y),10,(255,0,255),3)\n",
    "            #img = cv2.circle(img,(ojosd_x,ojosd_y),20,(255,0,255),3)\n",
    "\n",
    "            #cv2.imwrite(\"dataset/img_test/cerrar-ojos-12.jpg\", img)\n",
    "\n",
    "        crop_ojo_der = crop_face[ojode_new_y:ojode_new_y+ojo_h, ojode_new_x:ojode_new_x+ojo_w]\n",
    "        output = cv2.resize(crop_ojo_der, (200,200))\n",
    "            #cv2.imwrite(\"dataset/img_test/resize_ojo.jpg\", crop_ojo_der)\n",
    "        x=image.img_to_array(output)\n",
    "        x=np.expand_dims(x, axis=0)\n",
    "        images = np.vstack([x])\n",
    "        classes = None\n",
    "        classes = model.predict(images, batch_size=10)\n",
    "\n",
    "        if classes >=0.5:\n",
    "            texto = 'Ojo Izquierdo abierto'\n",
    "            cv2.putText(img, texto, (10,10), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 0, 0), 3)\n",
    "            cv2.putText(img, texto, (10,10), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)\n",
    "\n",
    "        elif classes < 0.5:\n",
    "            texto = 'Ojo Izquierdo cerrado'\n",
    "            cv2.putText(img, texto, (b_d[0], b_d[1] - 30), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 0, 0), 3)\n",
    "            cv2.putText(img, texto, (b_d[0], b_d[1] - 30), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)\n",
    "\n",
    "        crop_ojo_iz = crop_face[ojoiz_new_y:ojoiz_new_y+ojo_h, ojoiz_new_x:ojoiz_new_x+ojo_w]\n",
    "        output_1 = cv2.resize(crop_ojo_iz, (200,200)) \n",
    "            #cv2.imwrite(\"dataset/img_test/resize_1.jpg\", crop_ojo_iz)\n",
    "        x_1=image.img_to_array(output_1)\n",
    "        x_1=np.expand_dims(x_1, axis=0)\n",
    "        images_1 = np.vstack([x_1])\n",
    "        classes_1 = None\n",
    "        classes_1 = model.predict(images_1, batch_size=10)\n",
    "\n",
    "        if classes_1 >=0.5:\n",
    "            texto = 'Ojo derecho abierto'\n",
    "            cv2.putText(img, texto, (10,10), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 0, 0), 3)\n",
    "            cv2.putText(img, texto, (10,10), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)\n",
    "\n",
    "        elif classes_1 < 0.5:\n",
    "            texto = 'Ojo derecho cerrado'\n",
    "            cv2.putText(img, texto, (30,30), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 0, 0), 3)\n",
    "            cv2.putText(img, texto, (30,30), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)\n",
    "\n",
    "    else:\n",
    "        print(' no se reconocio los ojos')\n",
    "        \n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.imwrite(\"dataset/img_test/result.jpg\", img)\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
